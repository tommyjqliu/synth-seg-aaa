{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perlin Noise SynthSeg\n",
    "env: python3.8 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Perlin noise with parameters:\n",
      "Grid size: (110, 104, 126)\n",
      "Scale: 6.911655714027905\n",
      "Octaves: 6\n",
      "Persistence: 0.44694719794020094\n",
      "Lacunarity: 1.9911592141651353\n",
      "Threshold: 0.5798468454312964\n",
      "Minimum cloud size: 39776\n",
      "Seed: 96\n",
      "Generating Perlin noise with parameters:\n",
      "Grid size: (110, 104, 126)\n",
      "Scale: 4.376846168147354\n",
      "Octaves: 6\n",
      "Persistence: 0.5782777869998654\n",
      "Lacunarity: 2.1904969136110317\n",
      "Threshold: 0.6217848634167679\n",
      "Minimum cloud size: 2744\n",
      "Seed: 299\n"
     ]
    }
   ],
   "source": [
    "from SynthSegAAA.perlin_noise import randomize_perlin_label\n",
    "from ext.lab2im import utils\n",
    "import numpy as np\n",
    "\n",
    "lab = utils.load_volume(\"data/uwa_aaa_combined/Patient1_combined.nii.gz\", dtype='int', aff_ref=np.eye(4))\n",
    "output = randomize_perlin_label(lab, target=0, layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28cf55692534b939b2e7c8f4c8617ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index_0', max=125), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.check_image import check_image\n",
    "\n",
    "check_image(\n",
    "    [\n",
    "        {\"image\": output , \"title\": \"image\", \"is_label\": False},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from SynthSegAAA.brain_generator import BrainGenerator\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "input_label_path = \"data/uwa_aaa_combined\"\n",
    "image_path = \"data/Dataset002_perlin_aaa/imagesTr\"\n",
    "label_path = \"data/Dataset002_perlin_aaa/labelsTr\"\n",
    "os.makedirs(image_path, exist_ok=True)\n",
    "os.makedirs(label_path, exist_ok=True)\n",
    "label_files = os.listdir(input_label_path)\n",
    "label_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Patient10_combined.nii.gz (1/21) (88, 84, 100)\n",
      "Processing Patient11_combined.nii.gz (2/21) (120, 146, 232)\n",
      "Processing Patient12_combined.nii.gz (3/21) (236, 168, 246)\n",
      "Processing Patient13_combined.nii.gz (4/21) (172, 124, 280)\n",
      "Processing Patient14_combined.nii.gz (5/21) (198, 150, 194)\n",
      "Processing Patient15_combined.nii.gz (6/21) (120, 108, 150)\n",
      "Processing Patient16_combined.nii.gz (7/21) (172, 170, 250)\n",
      "Processing Patient17_combined.nii.gz (8/21) (222, 136, 244)\n",
      "Processing Patient18_combined.nii.gz (9/21) (126, 122, 128)\n",
      "Processing Patient1_combined.nii.gz (10/21) (110, 104, 126)\n",
      "Processing Patient20_combined.nii.gz (11/21) (152, 134, 218)\n",
      "Processing Patient26_combined.nii.gz (12/21) (112, 110, 118)\n",
      "Processing Patient32_combined.nii.gz (13/21) (96, 86, 148)\n",
      "Processing Patient33_combined.nii.gz (14/21) (114, 86, 154)\n",
      "Processing Patient34_combined.nii.gz (15/21) (164, 118, 154)\n",
      "Processing Patient35_combined.nii.gz (16/21) (94, 108, 126)\n",
      "Processing Patient3_combined.nii.gz (17/21) (70, 64, 120)\n",
      "Processing Patient5_combined.nii.gz (18/21) (110, 88, 80)\n",
      "Processing Patient6_combined.nii.gz (19/21) (74, 78, 114)\n",
      "Processing Patient8_combined.nii.gz (20/21) (196, 190, 134)\n",
      "Processing Patient9_combined.nii.gz (21/21) (138, 108, 118)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.nrrd2nii import nrrd2nii\n",
    "\n",
    "\n",
    "for i, label_file in enumerate(label_files):\n",
    "    label = nib.load(os.path.join(input_label_path, label_file))\n",
    "    print(f\"Processing {label_file} ({i + 1}/{len(label_files)})\", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Generating brains:   0%|          | 0/9 [00:00<?, ?it/s]2025-04-16 13:45:22.118397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2025-04-16 13:45:22.388485: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 13:45:22.388525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.755GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2025-04-16 13:45:22.389168: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2025-04-16 13:45:22.389462: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2025-04-16 13:45:22.414449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2025-04-16 13:45:22.418200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2025-04-16 13:45:22.418543: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2025-04-16 13:45:22.418720: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2025-04-16 13:45:22.418950: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-16 13:45:22.419001: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-04-16 13:45:22.419734: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2025-04-16 13:45:22.429673: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2495995000 Hz\n",
      "2025-04-16 13:45:22.432085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2e48000b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-16 13:45:22.432102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-04-16 13:45:22.433629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-04-16 13:45:22.433643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n",
      "Generating brains: 100%|██████████| 9/9 [02:13<00:00, 14.84s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from SynthSegAAA.brain_generator import BrainGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "input_label_path = \"data/nnunet_raw/Dataset001_raw_aaa/labelsTr\"\n",
    "image_path = \"data/nnunet_raw/Dataset003_perlin_synthseg/imagesTr\"\n",
    "label_path = \"data/nnunet_raw/Dataset003_perlin_synthseg/labelsTr\"\n",
    "os.makedirs(image_path, exist_ok=True)\n",
    "os.makedirs(label_path, exist_ok=True)\n",
    "label_files = os.listdir(input_label_path)\n",
    "label_files.sort()\n",
    "selected_num = 9\n",
    "generate_times = 1\n",
    "count = 0\n",
    "\n",
    "# Calculate total iterations for progress bar\n",
    "total_iterations = len(label_files[:selected_num]) * generate_times\n",
    "\n",
    "# Add tqdm progress bar\n",
    "with tqdm(total=total_iterations, desc=\"Generating brains\") as pbar:\n",
    "    for label_file in label_files[:selected_num]:\n",
    "        brain_generator = BrainGenerator(\n",
    "            os.path.join(input_label_path, label_file), \n",
    "            generation_labels=np.array([0, 1, 2, 3]),\n",
    "            output_labels=np.array([0, 1, 2, 0]),\n",
    "        )\n",
    "        for i in range(generate_times):\n",
    "            image, label = brain_generator.generate_brain()\n",
    "            nib.save(\n",
    "                nib.Nifti1Image(image, np.eye(4)),\n",
    "                os.path.join(image_path, f\"aaa_{count:03d}_0000.nii.gz\"),\n",
    "            )\n",
    "            nib.save(\n",
    "                nib.Nifti1Image(label, np.eye(4)),\n",
    "                os.path.join(label_path, f\"aaa_{count:03d}.nii.gz\"),\n",
    "            )\n",
    "            count += 1\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c500c436ded4326a14585136f673ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index_0', max=193), IntSlider(value=0, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from utils.check_image import check_image\n",
    "import nibabel as nib\n",
    "from utils.nrrd2nii import nrrd2nii\n",
    "\n",
    "id = \"000\"\n",
    "label = nib.load(f\"{label_path}/aaa_004.nii.gz\").get_fdata()\n",
    "image = nib.load(f\"{image_path}/aaa_004_0000.nii.gz\").get_fdata()\n",
    "check_image(\n",
    "    [\n",
    "        {\"image\": label, \"title\": \"label\", \"is_label\": True},\n",
    "        {\"image\": image, \"title\": \"image\", \"is_label\": False},\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_seg_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
