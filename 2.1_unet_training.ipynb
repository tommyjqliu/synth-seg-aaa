{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentatation\n",
    "ref:\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md \n",
    "\n",
    "\n",
    "env: python3.12 torch\n",
    "\n",
    "## Example dataset.json:\n",
    "```json\n",
    "{\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"CT\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"blood\": 1,\n",
    "        \"aaa\": 2\n",
    "    },\n",
    "    \"numTraining\": 50,\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: nnUNet_raw=data/nnunet_raw\n",
      "env: nnUNet_preprocessed=data/nnunet_preprocessed\n",
      "env: nnUNet_results=data/nnunet_results\n",
      "Fingerprint extraction...\n",
      "Dataset002_perlin_aaa\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|███████████████████████████████████████████| 50/50 [00:05<00:00,  9.39it/s]\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [213. 130. 149.], 3d_lowres: [213, 130, 149]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 127, 'patch_size': (np.int64(160), np.int64(160)), 'median_image_size_in_voxels': array([130., 149.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(160), np.int64(112), np.int64(128)), 'median_image_size_in_voxels': array([213., 130., 149.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 1, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to data/nnunet_preprocessed/Dataset002_perlin_aaa/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset002_perlin_aaa\n",
      "Configuration: 2d...\n",
      "100%|███████████████████████████████████████████| 50/50 [00:21<00:00,  2.29it/s]\n",
      "Configuration: 3d_fullres...\n",
      "100%|███████████████████████████████████████████| 50/50 [00:31<00:00,  1.61it/s]\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset002_perlin_aaa. Skipping.\n"
     ]
    }
   ],
   "source": [
    "%env nnUNet_raw=data/nnunet_raw\n",
    "%env nnUNet_preprocessed=data/nnunet_preprocessed\n",
    "%env nnUNet_results=data/nnunet_results\n",
    "\n",
    "!nnUNetv2_plan_and_preprocess -d 2 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-04-15 15:31:11.111419: Using torch.compile...\n",
      "2025-04-15 15:31:11.904691: do_dummy_2d_data_aug: False\n",
      "2025-04-15 15:31:11.904968: Using splits from existing split file: data/nnunet_preprocessed/Dataset002_perlin_aaa/splits_final.json\n",
      "2025-04-15 15:31:11.905304: The split file contains 5 splits.\n",
      "2025-04-15 15:31:11.905384: Desired fold for training: 0\n",
      "2025-04-15 15:31:11.905419: This split has 40 training and 10 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 127, 'patch_size': [160, 160], 'median_image_size_in_voxels': [130.0, 149.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset002_perlin_aaa', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [213, 130, 149], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0000001192092896, 'mean': 0.4888407588005066, 'median': 0.5051594972610474, 'min': 0.0018135346472263336, 'percentile_00_5': 0.017180923372507095, 'percentile_99_5': 0.9956796169281006, 'std': 0.2409818470478058}}} \n",
      "\n",
      "2025-04-15 15:31:14.062399: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-04-15 15:31:14.093555: \n",
      "2025-04-15 15:31:14.094205: Epoch 0\n",
      "2025-04-15 15:31:14.099330: Current learning rate: 0.01\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/nnunetv2/run/run_training.py\", line 267, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "^C\n",
      "object address  : 0x7f010ef10880\n",
      "object refcount : 3\n",
      "object type     : 0x94a7c0\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n",
      "Process Process-5:\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-7:\n",
      "Process Process-3:\n",
      "Process Process-6:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 49, in producer\n",
      "    if abort_event.is_set():\n",
      "       ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 335, in is_set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 240, in __exit__\n",
      "    return self._lock.__exit__(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 97, in __exit__\n",
      "    def __exit__(self, *args):\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 64, in producer\n",
      "    sleep(wait_time)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 67, in producer\n",
      "    abort_event.set()\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 342, in set\n",
      "    with self._cond:\n",
      "         ^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 237, in __enter__\n",
      "    return self._lock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tommy/miniconda3/envs/nnUNet/lib/python3.12/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# !nnUNet_n_proc_DA=8 nnUNetv2_train 2 2d all\n",
    "\n",
    "!nnUNet_n_proc_DA=8 nnUNetv2_train 2 2d 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
      "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
      "                      [-num_gpus NUM_GPUS] [--npz] [--c] [--val] [--val_best]\n",
      "                      [--disable_checkpointing] [-device DEVICE]\n",
      "                      dataset_name_or_id configuration fold\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset name or ID to train with\n",
      "  configuration         Configuration that should be trained\n",
      "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
      "                        between 0 and 4.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
      "                        Default: nnUNetTrainer\n",
      "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
      "                        identifier. Default: nnUNetPlans\n",
      "  -pretrained_weights PRETRAINED_WEIGHTS\n",
      "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
      "                        as pretrained model. Will only be used when actually\n",
      "                        training. Beta. Use with caution.\n",
      "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
      "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
      "                        validation as npz files (in addition to predicted\n",
      "                        segmentations). Needed for finding the best ensemble.\n",
      "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
      "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
      "                        Requires training to have finished.\n",
      "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
      "                        with the checkpoint_best instead of checkpoint_final.\n",
      "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
      "                        This will use the same 'validation' folder as the\n",
      "                        regular validation with no way of distinguishing the\n",
      "                        two!\n",
      "  --disable_checkpointing\n",
      "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
      "                        Ideal for testing things out and you dont want to\n",
      "                        flood your hard drive with checkpoints.\n",
      "  -device DEVICE        Use this to set the device the training should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "/home/tommy/miniconda3/envs/next-synthseg/lib/python3.12/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n",
      "There are 5 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 5 cases that I would like to predict\n",
      "\n",
      "Predicting aaa_000:\n",
      "perform_everything_on_device: True\n",
      "100%|█████████████████████████████████████████| 126/126 [00:03<00:00, 40.05it/s]\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with aaa_000\n",
      "\n",
      "Predicting aaa_001:\n",
      "perform_everything_on_device: True\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 49.02it/s]\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with aaa_001\n",
      "\n",
      "Predicting aaa_002:\n",
      "perform_everything_on_device: True\n",
      "100%|█████████████████████████████████████████| 462/462 [00:09<00:00, 51.27it/s]\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with aaa_002\n",
      "\n",
      "Predicting aaa_003:\n",
      "perform_everything_on_device: True\n",
      "100%|███████████████████████████████████████| 1464/1464 [00:27<00:00, 52.66it/s]\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with aaa_003\n",
      "\n",
      "Predicting aaa_004:\n",
      "perform_everything_on_device: True\n",
      "100%|█████████████████████████████████████████| 560/560 [00:10<00:00, 51.23it/s]\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with aaa_004\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_predict -i \"data/nnunet_raw/Dataset001_aaa/imagesTs\" -o \"data/nnunet_results/Dataset001_aaa/labelsTs\" -d 1 -c 2d -f 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd82ee1ed1d49a28b08f2977658035f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_index_0', max=125), IntSlider(value=0, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = nib.load(\n",
    "    \"data/nnunet_raw/Dataset001_aaa/imagesTs/aaa_000_0000.nii.gz\"\n",
    ").get_fdata()\n",
    "label = nib.load(\n",
    "    \"data/nnunet_results/Dataset001_aaa/labelsTs/aaa_000.nii.gz\"\n",
    ").get_fdata()\n",
    "ground_truth = nib.load(\n",
    "    \"data/nnunet_raw/Dataset001_aaa/labelsTs/aaa_000.nii.gz\"\n",
    ").get_fdata()\n",
    "check_image(\n",
    "    [\n",
    "        {\"image\": label, \"title\": \"label\", \"is_label\": True},\n",
    "        {\"image\": ground_truth, \"title\": \"ground_truth\", \"is_label\": True},\n",
    "        {\"image\": image, \"title\": \"image\", \"is_label\": False},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110, 104, 126), (110, 104, 126))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape,ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score for class 1: 0.8638\n",
      "Dice score for class 2: 0.8659\n",
      "Mean Dice score: 0.8649\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_dice_score(pred, target):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    pred = torch.from_numpy(pred).float()\n",
    "    target = torch.from_numpy(target).float()\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    pred = pred.flatten()\n",
    "    target = target.flatten()\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    \n",
    "    # Calculate Dice score\n",
    "    dice = (2. * intersection) / (union + 1e-8)  # Adding small epsilon to avoid division by zero\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "# Calculate Dice score for each class\n",
    "num_classes = int(max(label.max(), ground_truth.max())) + 1\n",
    "dice_scores = []\n",
    "\n",
    "for class_id in range(1, num_classes):  # Skipping background class (0)\n",
    "    pred_class = (label == class_id).astype(int)\n",
    "    target_class = (ground_truth == class_id).astype(int)\n",
    "    dice_score = calculate_dice_score(pred_class, target_class)\n",
    "    dice_scores.append(dice_score)\n",
    "    print(f\"Dice score for class {class_id}: {dice_score:.4f}\")\n",
    "\n",
    "# Calculate mean Dice score\n",
    "mean_dice = sum(dice_scores) / len(dice_scores)\n",
    "print(f\"Mean Dice score: {mean_dice:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnUNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
